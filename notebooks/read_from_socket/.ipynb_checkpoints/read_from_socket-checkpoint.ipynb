{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20907afa-2518-4c30-9932-8966870930fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masuk ke container jupiter\n",
    "docker exec -it <id> /bin/bash\n",
    "\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt-get install ncat\n",
    "\n",
    "ncat -v\n",
    "\n",
    "ncat -lk 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e123a5a-50ed-461d-87f2-46510dc14641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d2d7089755e7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>reading from socket</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ecea77b7810>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession \n",
    "    .builder \n",
    "    .appName(\"reading from socket\") \n",
    "    .master(\"local[*]\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d8fdf0-d8ec-452b-88b4-aa35593b1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/read_from_socket\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434cae7e-fc08-44b4-af48-ebb7e05fa42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark.read.format('text').load('/home/jovyan/work/read_from_socket/example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bbe3491-2d90-4b72-afb2-70947c6b11d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25673de8-81d2-4613-84a5-79085abc2a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|simon had a dog a...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce0d75f-cab2-41d1-b8f2-25e07bb51a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "df_words = df_raw.withColumn('words', split('value',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a26d76eb-4bed-4baf-bd9a-c66fe83c36df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               value|               words|\n",
      "+--------------------+--------------------+\n",
      "|simon had a dog a...|[simon, had, a, d...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f948d41e-3b5f-4175-a844-ef310a4db0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df_explode = df_words.withColumn('word', explode('words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a68d0ca-aca2-46a0-8b61-543dcdfa011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|               value|               words| word|\n",
      "+--------------------+--------------------+-----+\n",
      "|simon had a dog a...|[simon, had, a, d...|simon|\n",
      "|simon had a dog a...|[simon, had, a, d...|  had|\n",
      "|simon had a dog a...|[simon, had, a, d...|    a|\n",
      "|simon had a dog a...|[simon, had, a, d...|  dog|\n",
      "|simon had a dog a...|[simon, had, a, d...|  and|\n",
      "|simon had a dog a...|[simon, had, a, d...|    a|\n",
      "|simon had a dog a...|[simon, had, a, d...|  cat|\n",
      "|simon had a dog a...|[simon, had, a, d...|  the|\n",
      "|simon had a dog a...|[simon, had, a, d...|  dog|\n",
      "|simon had a dog a...|[simon, had, a, d...|  and|\n",
      "|simon had a dog a...|[simon, had, a, d...|  cat|\n",
      "|simon had a dog a...|[simon, had, a, d...| used|\n",
      "|simon had a dog a...|[simon, had, a, d...|   to|\n",
      "|simon had a dog a...|[simon, had, a, d...| love|\n",
      "|simon had a dog a...|[simon, had, a, d...|simon|\n",
      "+--------------------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_explode.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd9ca7b0-fdf8-4ca0-bc0d-e67bd26bf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode2 = df_words.withColumn('word', explode('words')).drop('value','words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cdb168f-4b13-4135-a053-7c686b4a4e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| word|\n",
      "+-----+\n",
      "|simon|\n",
      "|  had|\n",
      "|    a|\n",
      "|  dog|\n",
      "|  and|\n",
      "|    a|\n",
      "|  cat|\n",
      "|  the|\n",
      "|  dog|\n",
      "|  and|\n",
      "|  cat|\n",
      "| used|\n",
      "|   to|\n",
      "| love|\n",
      "|simon|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_explode2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28338f0-979b-4e31-ab4b-c7afc0bf2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, lit\n",
    "df_agg = df_explode2.groupby('word').agg(count(lit(1)).alias('cnt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96082bf5-2a5d-432c-b30f-38df4b87005a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| word|cnt|\n",
      "+-----+---+\n",
      "| used|  1|\n",
      "|simon|  2|\n",
      "|  dog|  2|\n",
      "| love|  1|\n",
      "|  had|  1|\n",
      "|  cat|  2|\n",
      "|  the|  1|\n",
      "|  and|  2|\n",
      "|    a|  2|\n",
      "|   to|  1|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_agg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06bb119-aba2-4ec3-9cf6-8aa3ca564d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d0f06-4dc8-4198-8280-0259ee391b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58c3b8-6a8c-4655-ac8d-88010dc9219d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e2c33-1b8b-4557-bafc-279b971f24ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be445c26-1d53-45cb-8645-725edc54c49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63811b-2122-4011-80c2-8039aed26f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f97c4c8-3cc4-411b-96f6-f78d816cbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9895d-2f3d-444b-ad1c-6505fa02b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import count, lit\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession \n",
    "    .builder \n",
    "    .appName(\"reading from socket\") \n",
    "    .master(\"local[1]\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "#read\n",
    "df_raw = spark.readStream.format('socket') \\\n",
    "              .option('host','localhost') \\\n",
    "              .option('port','9999') \\\n",
    "              .load()\n",
    "\n",
    "\n",
    "#transform\n",
    "df_words = df_raw.withColumn('words', split('value',' '))\n",
    "df_explode = df_words.withColumn('word', explode('words'))\n",
    "df_agg = df_explode.groupby('word').agg(count(lit(1)).alias('cnt'))\n",
    "\n",
    "#sink\n",
    "df_agg.writeStream \\\n",
    "      .format('console') \\\n",
    "      .outputMode('complete') \\\n",
    "      .start() \\\n",
    "      .awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b4fbac-6203-492e-8447-de3b23a7874c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1105b335-3a00-411a-883c-e8cb675dae58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "590de205-0384-438e-81ed-b634eb4e2a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4254aed6-b1ce-44a1-8680-aef1f4daf781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e499c40-ce25-4be3-ba8e-09fba71a5976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39664050-fcb8-4908-82d4-886cd7ccfc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
